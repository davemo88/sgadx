
\documentclass{article}

\usepackage[utf8]{inputenc}

\usepackage[T1]{fontenc}

\usepackage{geometry}
\geometry{a4paper}
 
\usepackage{float}
\restylefloat{table}
\usepackage[english]{babel}

\usepackage{setspace}
\doublespacing

\usepackage{amsfonts}
\usepackage{amsmath}

\usepackage{bm}

% \usepackage{tikz}
% \usetikzlibrary{trees}

% \usepackage{algorithm}
% \usepackage{algorithmic}

\usepackage{todonotes}
\usepackage{hyperref}

\title{Master's Thesis: Ads via Signaling Games}

\author{David Kasofsky}

\date{May 1, 2016}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

The goal of this paper is to demonstrate an application of game theory and machine learning in advertising. In particular, we model advertising interaction via signaling games and imagine the players as machine learning algorithms. Advertising is an appealing domain as it is a driving force in the success of the internet and motivates many challenging computer science problems.

\section{Advertising}
As the internet becomes the primary ad medium\cite{iab1}, advertising strategy, measurement, and implementation increasingly rely on big data, machine learning, and cloud computing. However twenty first century advertising has also motivated concerns about privacy.

Much of the activity on the internet generates data potentially useful in advertising strategy, e.g. website analytics or user demographic data. There is an incentive to store an enormous amount of data for use by advertisers. In turn, advertisers need data storage and processing frameworks which are suited to this setting, e.g. MapReduce\cite{mapreduce1}. All of this new data has generated interest in techniques that can make sense of it, e.g. targeted advertising \cite{displayadsml1}, ad evaluation \cite{abhishek2012media}, and real-time bidding algorithms \cite{yuan2014survey}.

There are two privacy concerns here. The first is that businesses may be observing and storing personal data that the consumer does not wish to share or persist. The second is that businesses may treat the consumer differently based on personal data to the possible detriment of the consumer. Consumers can be manipulated into making certain decisions \cite{akerlof2015phishing} and thus there is a balance to be struck between advertiser collection and exploitation of consumer data and consumer privacy.

Real-time bidding and personalized advertising are great examples of techniques in common use today. Advertisers use consumers' personal data in determining bid amounts in ad auctions as well as specific ad content to be shown. The main idea of this paper is to model personalized advertising as a game played by machine learning algorithms.

\section{Signaling Games}

A Signaling Game is a two-player game of information asymmetry. Signaling games appear in many interesting places: in mate selection by Zahavi\cite{zahavi1} and Grafen\cite{grafen1}, in job markets by Spence\cite{spence1}, in bargaining by Crawford\cite{crawford1982strategic} and in cybersecurity by Casey\cite{casey1}\cite{casey2}\cite{casey3}. Skyrms describes how signaling permeates life from bacteria up to humans \cite{skyrms2010signals}.

A signaling game is a game of imperfect information or a Bayesian game\cite{harsanyi2004games}. Players begin the game with prior beliefs about whatever information is hidden and these priors naturally influence the players' strategic choices. In a signaling game, some information is hidden asymmetrically and so one player has an information advantage over the other. 

The informed player is called the sender $S$ and the uninformed player the receiver $R$. The sender $S$ has a secret type $\tau \in T$ unknown to the receiver $R$. $S$ sends a signal $\sigma \in \Sigma$ to $R$ who then performs an action $\alpha \in A$. Players receive payoffs depending on the action $\alpha$, signal $\sigma$, and secret type $\tau$. This statement of the game is inspired by Sobel\cite{sobel1}.

\subsection{Definition of Signaling Game}
To define a signaling game we specify the following:
\begin{itemize}
    \item a type set $T$ of possible sender types
    \item distribution $D_T$ determining sender type $\tau \in T$
    \item receiver prior distribution $\pi$ over $T$
    \item signal set $\Sigma$ of possible signals
    \item action set $A$ of possible actions
    \item sender and receiver utility functions $\mu_S, \mu_R: T \times \Sigma \times A \longrightarrow \mathbb{R}$
\end{itemize}

\noindent Let $\alpha_\tau^* = \underset{\alpha \in A}{\text{max}} \mu_S(\tau, \cdot, \alpha)$, i.e. the action with maximum payoff to $S$. Similarly let $\tau_\alpha^* = \underset{\tau \in T}{\text{max}} \mu_R(\tau, \cdot, \alpha)$, i.e. the type with the maximum payoff to $R$ given the action $\alpha$. One could think of $\alpha_\tau^*$ as the action $S$ wishes he could get $R$ to perform if $S$ of type $\tau$ and $\tau_\alpha^*$ is the type $R$ hopes $S$ if $R$ performs action $\alpha$.

Define the relations $f_S: T \rightarrow A$ and $f_R: A \rightarrow T$ as:
\begin{align*}
    f_S(\tau) = \alpha_\tau^*;\\
    f_R(\alpha) = \tau_\alpha^*
\end{align*}

Consider the following interpretation of the utility functions motivated by rate-distortion functions in information theory.  The utility functions are functions of the form:
\begin{equation}
    \mu_S(\tau, \sigma, \alpha) = I_S(\tau, \sigma) + \lambda_S d_S(f_S(\tau), \alpha)
\label{sig_sender_util}
\end{equation}\begin{equation}
    \mu_R(\tau, \sigma, \alpha) = I_R(\sigma, \alpha) + \lambda_R d_R(f_R(\alpha), \tau)
\label{sig_receiver_util}
\end{equation}
\noindent The first term in \autoref{sig_sender_util} measures the amount of information conveyed by the signal about the type. The second term measures the difference between the desired action $\alpha_\tau^* = f_S(\tau)$ and the action performed by the receiver $\alpha$. Likewise the first term in \autoref{sig_receiver_util} measures the information gleaned from the signal in determining the action and the second term measures the difference between the sender's type and the ideal type $\tau_\alpha^*$ given the action $\alpha$.

This interpretation of the utility functions is a natural one. The message $\sigma$ in a signaling game conveys information about the secret type $\tau$. For example, suppose $\vert \Sigma \vert < \vert T \vert$. In this case it is not possible for $S$ to send a unique message for each type. Conversely $R$ cannot always deduce the type from the message and therefore cannot always perform the optimal action. When a message allows $R$ to deduce $\tau$, the information contained in the message is maximized. Furthermore there is no distortion, i.e. $R$ can choose $\alpha$ such that $f_R(\alpha) = \tau$. One could think of the type $\tau$ as data to be compressed via the signal $\sigma$.

However things are not quite so simple as the sender may wish to be deceptive. For instance, suppose $\tau \ne f_R(\alpha_\tau^*)$. In other words $S$ benefits most from an action that is undesirable for $R$. In this case $S$ wants to send a message that does \emph{not} convey the true value of $\tau$. $S$ wishes $R$ would believe $S$ is actually type $\tau^\prime = f_R(\alpha_\tau^*)$.

\subsection{Simple Poker}

Here we have a toy example of a signaling game: a simplified version of two-player poker. The sender $S$ is dealt either a winning hand or a losing hand and may check or bet. The receiver $R$ then may fold or call. The payoff matrix in \autoref{simplepokerpayoffs} shows the poker-inspired messages, actions, and payoffs.

\begin{table}[H]
	\centering
	\caption{Simple Poker Payoffs}
	\label{simplepokerpayoffs}
	\begin{tabular}{ll|l|l|}
		\cline{3-4}&       & \textbf{Fold} & \textbf{Call} \\ \hline
		\multicolumn{1}{|l|}{$\tau=\textbf{Winner}$} & \textbf{Check} & (1,-1)  & (1,-1)  \\ \cline{2-4}
		\multicolumn{1}{|l|}{}        & \textbf{Bet}   & (1,-1)  & (2,-2)  \\ \hline
		\multicolumn{1}{|l|}{$\tau=\textbf{Loser}$}  & \textbf{Check} & (1,-1)  & (-1,1)  \\ \cline{2-4}
		\multicolumn{1}{|l|}{}        & \textbf{Bet}   & (1,-1)  & (-2,2) \\ \hline
	\end{tabular}
\end{table}
A bet by the sender signals a winner and a check signals a loser. The receiver should fold if the sender has a winner and call if the sender has a loser. However the sender can bluff by betting with a loser and so there is the capacity for deception.

Suppose $S$ has a winning hand. Then bet dominates check for $S$ and fold dominates call for $R$. When $S$ has a losing hand then the opposite is true. Say $S$ bets all winners and checks all losers. Call this strategy $h_1$. If $S$ plays $h_1$, then $R$'s best response is to fold to all bets and call all checks ($g_1$). However $(h_1, g_1)$ is clearly not a Nash equilibrium of the game since $S$ has a different best response to $g_1$: bet every hand ($h_2$).

In considering $R$'s best response to $h_2$, we stumble across several interesting points. The first is that if $S$ bets every hand, i.e. the sender always sends the same signal regardless of the secret type, then $R$ cannot infer any information about the secret type from the signal. If this is the case, then $R$ has to make a guess about the sender's type $\tau$. For instance $R$ may guess that $S$ has a winning hand half the time, i.e. $P(\tau = \textbf{Winner}) = \frac{1}{2}$. Then $R$ could randomize uniformly between calling and folding ($g_2$). If the guess is correct then $(h_2, g_2)$ is a Nash equilibrium.

For a more formal statement of the game, we define $\left(T, \Sigma, A, \mu_S, \mu_R, \right)$, where:
\begin{itemize}
	\item $T = \lbrace 0, 1 \rbrace$ is the type set. To begin we chose some $\tau \in T$ as the type of $S$. 0 corresponds to loser and 1 to winner.
	\item $\Sigma = \lbrace 0, 1 \rbrace$ is the signal set. 0 corresponds to check and 1 to bet.
		\item $A = \lbrace 0, 1 \rbrace$ is the action set. 0 corresponds to fold and 1 to call.
	\item $\mu_S: T \times \Sigma \times A \longrightarrow \mathbb{R}$ is the sender's utility function:
		\begin{align*}
\mu_S(\tau, \sigma, \alpha) = \tau(1+\sigma\alpha) + (1-\tau)(1-\sigma\alpha-\alpha)
\mu_S(\tau, \sigma, \alpha) = \tau(1+\sigma\alpha) + (1-\tau)(1-\sigma\alpha-\alpha)
		\end{align*}
	\item $\mu_R: T \times \Sigma \times A \longrightarrow \mathbb{R}$ is the receiver's utility function:
		\begin{align*}
\mu_R(\tau, \sigma, \alpha) = \tau(-\sigma\alpha) + (1-\tau)(\sigma\alpha+\alpha)
\mu_R(\tau, \sigma, \alpha) = \tau(-\sigma\alpha) + (1-\tau)(\sigma\alpha+\alpha)
		\end{align*}
\end{itemize}

Let us further examine the above utility functions in terms of our rate-distortion interpretation. \todo{write these utility functions in the rate-distortion form}

\begin{align*}
\end{align*}

With this example under our belt, we have some 

We are particularly interested in how players can learn to play equilibrium strategies in repeated signaling games. First we note that signaling games are not zero-sum in general and so the standard minimax theorem of von Neumann does not apply. In order to make satisfying progress in this vein we look to the theory of learning with expert advice, online learning, and regret minimization alrogithms. These are topics from the theory of machine learning.

\section{Signaling Games in Advertising}

As mentioned, advertisers may tailor ad content for a specific consumer using that consumer's personal data. Here we cast this scenario as a signaling game. The advertiser is the sender and the consumer is the receiver. The sender's type describes the products that advertiser promotes. The message represents ad content. The action is the consumer's interaction with the ad.

We imagine ourselves in the common online advertiser scenario. A consumer visits a web page on which an advertiser may display an ad. The advertiser whatever data is available about the consumer to choose the ad to displayed. Finally the consumer may click on the ad if they find it appealing. In this game both sender and receiver have types: the sender's corresponding to the products the advertiser promotes the receiver's corresponding to the consumer's favored products.

The advertiser wants the consumer to click on the ad. The consumer, however, only wants to click on ads for the products they favor. This gives the advertiser an incentive to send an ad which appeals to consumer's type rather than represent their own type. This creates the potential for deception in the game.

Let us give a more formal statement. First we have the sender $S = (\tau_S, \pi_S, \Sigma, \mu_S, H)$, where:
\begin{itemize}
    \item $\tau_S \in T_S = \mathbb{R}^D$. $\tau_S$ is the type of $S$. $T_S$ is the type space of $S$.
    \item $\pi_S$ is a probability distribution over $T_R$, the type space of $R$.
    \item Signal space $\Sigma = \lbrace \sigma_1, ..., \sigma_n \vert \sigma_i \in \mathbb{R}^D \rbrace$ .
    \item Utility function $\mu_S: T_S \times \Sigma \times A \rightarrow \mathbb{R}$ is defined as:
    \begin{equation}
        \mu_S = \langle \tau_S, \sigma \rangle + \lambda_S \alpha \langle \sigma, \tau_R \rangle
    \end{equation}
\end{itemize}

\noindent Next we have the receiver $R = (\tau_R, \pi_R, A, \mu_R, G)$, where:
\begin{itemize}
    \item $\tau_R \in T_R = \mathbb{R}^D$.
    \item $\pi_R(\cdot|\sigma)$ is a conditional distribution over $T_S$.
    \item $A = \lbrace 0,1 \rbrace$. 0 corresponds to no click, 1 to click.
    \item Utility function $\mu_R: T_S \times T_R \times A \rightarrow \mathbb{R}$ is defined as:
    \begin{equation}
        \mu_R = \langle \tau_R, \sigma \rangle + \lambda_R \alpha \langle \sigma, \tau_S \rangle
    \end{equation}
\end{itemize}

\noindent The first twist in this game is that both $S$ and $R$ have types $\tau_S$ and $\tau_R$ respectively. These types are $D$-dimensional vectors. Each component of these vectors can be interpreted as an affinity for a product category. We can compare the types of $S$ and $R$ to determine the suitability of the advertiser's products for the consumer. Similarly both $S$ and $R$ have priors $\pi_S$ and $\pi_R$ over the other player's type space.

Furthermore, the ad $\sigma$ is also a $D$-dimensional vector. Once again we can interpret the components as product category affinities and imagine that the ad promotes certain types of products. The action $\alpha$ is binary, corresponding to whether or not the consumer clicks on the ad.

The sender's utility function $\mu_S$ punishes advertisers for deception, i.e. the advertiser incurs a cost as the ad differs from the advertiser's type. If the consumer clicks, the advertiser is rewarded for matching the consumer's type with their ad. 

The receiver's utility function $\mu_R$ rewards the receiver for clicking on ads for advertisers with suitable types. 

Loss in the iterated game is average (internal) regret after $T$ rounds. We expose the types of the players when we give payoffs but not their identity, i.e. players cannot recognize each other after meeting. By exposing the types we make this into a supervised online learning problem for each player.

\section{Learning and Games}

Learning theory is an appealing lens through which to examine games. It is natural to improve at a game as one plays. Following this experience, we imagine the players of our signaling games as learning algorithms. The data these algorithms learn from is the history of games they have played. Our presentation of the learning theory is inspired by \cite{mohri2012foundations}. 

As mentioned, we look to learning theory for direction in how players can learn to play equilibrium strategies in repeated signaling games. We begin with a review of online learning and learning with expert advice. This will bring us to regret minimization and how regret minimization can lead to equilbrium stratgies in games. Finally we discuss a refinement of regret minimization suitable for signaling games and the types of equilibirum we can hope to achieve.


\subsection{Online Learning}

In the online learning setting, the learning algorithm is given one data point at a time over the course of $T$ rounds. This is in contrast to the batch setting in which the entire dataset is available to algorithm at once. Thus there are a inherent limitations to the online setting, e.g. global properties of the data cannot be exploited while running the algorithm and there is no possibility for preprocessing.

This motivates techniques such as Sketched Online Newton\cite{luo2016efficient} which mitigate undesirable global properties without advance knowledge of them. In this example we may have ill-conditioned data which increases the error of algorithms like Online Gradient Descent\cite{zinkevich2003online}. If considered in the batch setting, the data could be made well-conditioned by application of a linear transformation to each point in the data set. However this option is unavailable in the online setting.

Another important distinction from the typical batch setting or PAC learning\cite{valiant1984theory} is that online learning makes no distributional assumption about the data. In fact the data can be generated in an adversarial fashion. In the typical batch setting we assume that all training samples are drawn from the same distribution in an IID fashion.

We can concisely present the standard online learning setting as follows:

\begin{itemize}
\item for $t = 1$ to $T$:
    \begin{itemize}
    \item receive $x_t$
    \item predict $\hat{y}_t = h(x_t; w_t)$
    \item receive $y_t$
    \item incur loss $L(y_t, \hat{y}_t)$
    \item update state $w_{t+1} \leftarrow w_t$
    \end{itemize}
\end{itemize}
\todo{use algorithm package to make this look nicer}

Thus 

\subsection{Learning with Expert Advice}

Learning with expert advice is a classic scenario in machine learning. For simplicity take the example of binary classification, i.e. we are given vector input $\textbf{X}$ and we must output a binary label $\textbf{Y} \in \lbrace -1,1 \rbrace$. We are given a set of experts who each predict a label for $X$. Our task is to accurately classify the inputs by using the predictions offered by the experts.

The experts need not be literal experts. A common scenario is to treat the input features as experts. A learning algrithm simply learn a linear combination of the features to make predictions. A similar treatment could use threshold functions of the features as experts, e.g. if $x_1 > \theta$ predict $1$ else $-1$. The experts could also simply be black boxes. For example each expert might be a machine learning algorithm itself.

When considering game theory, we might begin by imaging the moves available to the players as experts. We might learn a distriution over the moves, i.e. a mixed strategy.

\todo{incomplete. needs a couple references and better motivation}

\subsection{Regret}

\subsection{Weighted Majority}

talk about \cite{littlestone1994weighted}

\subsection{Swap Regret}

talk about \cite{blum2007external}, \cite{mohri2014conditional}

\subsection{Correlated Equilibrium}

talk about \cite{aumann1974subjectivity}, \cite{aumann1987correlated}, \cite{foster1997calibrated}

\section{Swap Regret Minimization in Signaling Games}

\section{References}

\bibliographystyle{amsplain}
\bibliography{dk_thesis}

\end{document}
